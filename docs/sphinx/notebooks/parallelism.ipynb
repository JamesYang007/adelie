{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Parallelism__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout `adelie`, there are multiple places where the user can specify the number of (OpenMP) threads.\n",
    "We have made the package flexible enough that one has high control over the number of threads\n",
    "in certain parts of the computation, \n",
    "e.g. linear algebra routines within the solver or inner-products with a matrix.\n",
    "However, this flexibility also allows for common pitfalls. \n",
    "In this notebook, we cover some tips on how to properly use parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adelie as ad\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Examples of Parallelism__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `adelie`, the two most common places where parallelism occurs is within the solver and the matrix class.\n",
    "There is no strict requirement that a matrix class needs to have parallelized routines,\n",
    "however, most of the provided matrix classes do support parallelism.\n",
    "\n",
    "As an example, we show below how to specify the number of threads for a dense matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100         # number of observations\n",
    "p = 1000        # number of features\n",
    "n_threads = 4   # number of threads\n",
    "seed = 0        # seed\n",
    "\n",
    "np.random.seed(seed)\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "X_wrap_1 = ad.matrix.dense(X, method=\"naive\")   # default n_threads=1\n",
    "X_wrap_4 = ad.matrix.dense(X, method=\"naive\", n_threads=n_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is implementation-specific detail for how multithreading is used,\n",
    "and is generally not to be concerned by the average user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows how to specify the number of threads for the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m     | 46/100 [00:00:00<00:00:00, 993.62it/s] [dev:90.6%]\n"
     ]
    }
   ],
   "source": [
    "# create response vector\n",
    "y = X[:, -1] * np.random.normal(0, 1) + np.random.normal(0, 1, n)\n",
    "state = ad.grpnet(\n",
    "    X=X,\n",
    "    glm=ad.glm.gaussian(y=y),\n",
    "    n_threads=n_threads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Common Number of Threads__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pitfall is to specify a different number of threads (greater than 1) \n",
    "within different sections of the algorithm.\n",
    "OpenMP incurs a lot of cost for switching the number of threads (at least on some machines),\n",
    "so we advise users to only specify two possible numbers at all times: 1 or `n_threads`\n",
    "where `n_threads` is some user-specified number.\n",
    "For example, we advise _against_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m     | 46/100 [00:00:00<00:00:00, 59.94it/s] [dev:90.6%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 437 ms, total: 1.56 s\n",
      "Wall time: 770 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_wrap = ad.matrix.dense(X, method=\"naive\", n_threads=2)\n",
    "state = ad.grpnet(\n",
    "    X=X_wrap,\n",
    "    glm=ad.glm.gaussian(y=y),\n",
    "    n_threads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we advise for the following cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m     | 46/100 [00:00:00<00:00:00, 1223.99it/s] [dev:90.6%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 19.2 ms, total: 153 ms\n",
      "Wall time: 41.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_wrap = ad.matrix.dense(X, method=\"naive\", n_threads=1)\n",
    "state = ad.grpnet(\n",
    "    X=X_wrap,\n",
    "    glm=ad.glm.gaussian(y=y),\n",
    "    n_threads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m     | 46/100 [00:00:00<00:00:00, 1310.90it/s] [dev:90.6%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 6.71 ms, total: 141 ms\n",
      "Wall time: 37.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_wrap = ad.matrix.dense(X, method=\"naive\", n_threads=4)\n",
    "state = ad.grpnet(\n",
    "    X=X_wrap,\n",
    "    glm=ad.glm.gaussian(y=y),\n",
    "    n_threads=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m\u001b[1;32m█\u001b[0m     | 46/100 [00:00:00<00:00:00, 1116.50it/s] [dev:90.6%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 0 ns, total: 176 ms\n",
      "Wall time: 44.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_wrap = ad.matrix.dense(X, method=\"naive\", n_threads=4)\n",
    "state = ad.grpnet(\n",
    "    X=X_wrap,\n",
    "    glm=ad.glm.gaussian(y=y),\n",
    "    n_threads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see about 20x speedup by keeping the number of threads _consistent_ throughout the algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Optimal Number of Threads__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a question of the optimal number of threads to use.\n",
    "This is completely application and hardware dependent and cannot be answered universally.\n",
    "Our only advice is to experiment with the number of threads (while following the rest of the tips).\n",
    "Our experience shows that most of the time, i.e. with small to moderately sized data,\n",
    "single-threaded runs are actually the fastest because the OpenMP thread management cost dominates.\n",
    "We only recommend increasing the number of threads for large data.\n",
    "Even then, you may experience negligible improvements since multithreading is oftentimes bottlenecked\n",
    "by memory bandwidth.\n",
    "So machines with more NUMA nodes, larger RAM, or faster RAM access \n",
    "(e.g. large machines in a cluster) will reap more benefits from parallelism. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adelie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
